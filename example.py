# -*- coding: utf-8 -*-
"""example.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/157VVg1ev_AOvd6O0xLMiJATf8_YtcbjJ

Decision tree classifir
"""

# Commented out IPython magic to ensure Python compatibility.
#Loading Libraries
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

import sklearn.datasets as datasets
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve
from sklearn.tree import plot_tree

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV

from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

import pandas as pd
df=pd.read_csv('/content/Breast Cancer.csv')
df.head()

# To know number of rows and collumns
df.shape

# Check the dataframe information
df.info()

# To find if any null value is present
df.isnull().sum()

# To see summary statistics
df.describe().T

# To find outliers
cols = df.columns[0:-1]
for i in cols:
  sns.boxplot(v=df[i])
  plt.show()

# Splitting the data into train and test sets
X = df.drop("diagnosis",axis=1)
y = df["diagnosis"]
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3, random_state= 1)

# Plotting of decission tree
from IPython.display import Image
from sklearn.tree import export_graphviz

!pip install pydotplus
import pydotplus


features = X.columns
dot_data = export_graphviz(df, out_file=None, feature_names=features)
graph = pydotplus.graph_from_dot_data(dot_data)
Image(graph.create_png())

"""support vector model"""

import pandas as pd
from sklearn.model_selection import train_test_split

df=pd.read_csv('/content/Fish.csv')

x=df[['LIVE_BAIT','CAMPER','PERSONS','CHILDREN']]
y=df['FISH_COUNT']

print("Shape of the dataset :",df.shape)
print("Five columns of dataset :\n",df.head())

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=109)

from sklearn import svm

clf=svm.SVC(kernel='linear')
clf.fit(x_train,y_train)

xtest=clf.predict(x_test)

from sklearn.metrics import accuracy_score,classification_report

print("Accuracy of the model is :",accuracy_score(y_test,xtest))

print("classification reort of the model is:",classification_report(y_test,xtest))

"""1.Python Implementation of K-Means clustering Algorithm."""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

data = pd.read_csv('/content/mallcustomer.csv')
x = data.iloc[:, [3, 4]].values

# Determine the optimal number of clusters using the elbow method
wc = []
for i in range(1, 11):
  kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)
  kmeans.fit(x)
  wc.append(kmeans.inertia_)

# Plot the elbow method graph
plt.plot(range(1, 11), wc)
plt.title("The Elbow Method Graph")
plt.xlabel("Number of Clusters")
plt.ylabel("WCSS (Within-Cluster Sum of Squares)")
plt.show()

# Perform K-means clustering with 5 clusters
num_clusters = 5
kmeans = KMeans(n_clusters=num_clusters, init='k-means++',
random_state=42)
y_predict = kmeans.fit_predict(x)

# Visualize the clusters
for cluster_num in range(num_clusters):
  plt.scatter(x[y_predict == cluster_num, 0], x[y_predict == cluster_num, 1],
s=100, label=f'Cluster {cluster_num + 1}')

plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300,
c='yellow', label='Centroid')
plt.title('Clusters of customers (5 clusters)')
plt.xlabel('Annual Income (k$)')
plt.ylabel('Spending Score (1-100)')
plt.legend()
plt.show()

"""1.Build Logistic regression model in python."""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
from sklearn.datasets import load_iris

# Load the Iris dataset
iris = load_iris()
X,y=iris.data,iris.target

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y,
test_size=0.2, random_state=42)

# Create the Logistic Regression model
model = LogisticRegression()
model.fit(X_train, y_train)

# Make predictions and evaluate the model
y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print("Accuracy:", accuracy)
print("Classification Report:\n", report)

"""2. Build decision tree-based model inpython for like Breast Cancer
Wisconsin(diagnostic) dataset from sci-kit learn Or any classification
dataset from UCI ,Kaggle.
"""

from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
import pandas as pd

breast=load_breast_cancer ()
x,y=breast.data,breast.target

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=50)

clf=DecisionTreeClassifier()
clf=clf.fit(x_train,y_train)

xtrain=clf.predict(x_train)
xtest=clf.predict(x_test)

print("Accuracy of the Traindata:",accuracy_score(y_train,xtrain))
print("Accuracy of the Test data :",accuracy_score(y_test,xtest))